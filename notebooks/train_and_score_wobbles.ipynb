{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "def postgresql_engine(user, pwd, host, port, dbname):\n",
    "    # Need pyycopg2-binary package\n",
    "    sql_engine = create_engine('postgres://' + user + ':' + pwd + '@' + host + ':' + port + '/' + dbname, echo=False)\n",
    "    return sql_engine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# DB username and password\n",
    "import getpass\n",
    "\n",
    "user = getpass.getpass()\n",
    "pwd = getpass.getpass()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# misc db parameters\n",
    "host= 'adds-postgres-dev.cfgztrijqgvp.us-east-1.rds.amazonaws.com'\n",
    "dbname= 'musiclab'\n",
    "port= '5432'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# get callout research for songs released in the past 2 years\n",
    "data_query_train = '''\n",
    "Select *\n",
    "from adds_temp.demo_rr_features_h1 as rdfh\n",
    "where pop_all is not null\n",
    "and breakout_name = 'Total'\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "filter_rules = '''and song_weeks_since_last_spins <=13\n",
    "and ((song_last_test_co_weeks <=26)\n",
    "or (song_last_test_omt_weeks <=104)\n",
    "or format_code in ('u4','l2'))\n",
    "and (((station_test_1_plus=0 and station_test_1_id=1) or station_test_1_plus>0) or format_code in ('u4','l2'))\n",
    "and (format_code<>'h1' or station_id<>3323403)\n",
    "and (format_code<>'c1' or station_id<>3322825)\n",
    "and (format_code<>'a2' or station_id<>3322799 or gcr<>'G')\n",
    "and taa_quintile is not null\n",
    "and gcr_adj is not null\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "engine = postgresql_engine(user, pwd, host, port, dbname)\n",
    "with engine.connect() as con:\n",
    "    with con.connect():\n",
    "        df_train = pd.read_sql(data_query_train + filter_rules, con=con)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_train.sort_values(by=['station_id', 'mediabase_id', 'breakout_name', 'week_dt', ], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# define demo segments and categories\n",
    "breakout_category = {'*Core*': 'Core-Cume', '*Old*': 'Age', '*Young*': 'Age', 'Total': 'Total', 'White': 'Race',\n",
    "                     'Non-Core': 'Core-Cume',\n",
    "                     'Hispanic': 'Race', 'AA': 'Race', 'F': 'Gender', 'M': 'Gender', 'WAO': 'Race',\n",
    "                     'F (25-29)': 'Gender', 'F (20-24)': 'Gender', 'F (18-29)': 'Gender', 'F (17-29)': 'Gender',\n",
    "                     'F (20-23)': 'Gender', 'F (18-39)' : 'Gender',\n",
    "                     'F (16-24)': 'Gender', 'F (30-34)': 'Gender', 'F (18-34)': 'Gender', 'F (24-29)': 'Gender',\n",
    "                     'F (17-19)': 'Gender', 'F (15-26)': 'Gender', 'F (15-19)': 'Gender', 'F (15-24)': 'Gender',\n",
    "                     'F (18-24)': 'Gender', 'F (20-29)': 'Gender', 'F (25-34)': 'Gender', 'F (Other)': 'Gender'}\n",
    "\n",
    "breakout_map = {'*Core*': 'Core', '*Old*': 'Old', '*Young*': 'Young', 'Total': 'Total', 'White': 'White',\n",
    "                'Non-Core': 'Non-Core',\n",
    "                'Hispanic': 'Hispanic', 'AA': 'AA', 'F': 'Female', 'M': 'Male', 'WAO': 'White', 'F (25-29)': 'Female',\n",
    "                'F (20-24)': 'Female', 'F (18-29)': 'Female', 'F (17-29)': 'Female', 'F (20-23)': 'Female',\n",
    "                'F (16-24)': 'Female', 'F (30-34)': 'Female', 'F (18-34)': 'Female', 'F (24-29)': 'Female',\n",
    "                'F (17-19)': 'Female', 'F (18-39)' : 'Female',\n",
    "                'F (15-26)': 'Female', 'F (15-19)': 'Female', 'F (15-24)': 'Female',\n",
    "                'F (18-24)': 'Female_(18-24)', 'F (20-29)': 'Female', 'F (25-34)': 'Female',\n",
    "                'F (Other)': 'Female_Other'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# create segment and category fields\n",
    "df_train['segment'] = df_train['breakout_name'].apply(func=(lambda x: breakout_map[x] if (x in breakout_map.keys()) else None))\n",
    "df_train['demo_category'] = df_train['breakout_name'].apply(func=(lambda x: breakout_category[x] if x in breakout_category.keys() else None))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# drop misc female breakouts\n",
    "drop_idx = df_train[(df_train['segment'] == 'Female') | (pd.isna(df_train['segment']))].index\n",
    "df_train.drop(drop_idx, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Drop songs with just a single score in the past 2 years\n",
    "df_train_week_ct = pd.DataFrame(df_train.groupby(['station_id', 'mediabase_id', 'breakout_id'])['week_dt'].count())\n",
    "drop_idx = df_train.join(df_train_week_ct[df_train_week_ct['week_dt'] == 1], on=['station_id', 'mediabase_id', 'breakout_id'], how='right', rsuffix='_r').index\n",
    "df_train.drop(index=drop_idx, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "demo_category  segment         taa_quintile\nAge            Old             1                2252\n                               2                6295\n                               3                6168\n                               4                8090\n                               5               21146\n               Young           1                2252\n                               2                6295\n                               3                6173\n                               4                8088\n                               5               21143\nCore-Cume      Core            1                2251\n                               2                6293\n                               3                6169\n                               4                8089\n                               5               21150\n               Non-Core        1                2242\n                               2                6266\n                               3                6147\n                               4                8039\n                               5               21049\nGender         Female_(18-24)  1                2064\n                               2                5963\n                               3                5678\n                               4                7388\n                               5               18942\n               Female_Other    1                2064\n                               2                5960\n                               3                5680\n                               4                7387\n                               5               18943\nRace           AA              1                  82\n                               2                 234\n                               3                 325\n                               4                 583\n                               5                1680\n               Hispanic        1                1559\n                               2                4353\n                               3                4130\n                               4                5280\n                               5               13842\n               White           1                2250\n                               2                6595\n                               3                6431\n                               4                8478\n                               5               22208\nTotal          Total           1                2252\n                               2                6294\n                               3                6170\n                               4                8083\n                               5               21133\nName: mediabase_id, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(['demo_category', 'segment', 'taa_quintile'])['mediabase_id'].count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### isolate numeric and categorical columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# constants\n",
    "num_cols_like = ['artist_count', 'feat_artist', 'feat_artist_song', 'mscore', 'spins','pop_prior',\n",
    "                 'pop_artist_prior', 'song_age_weeks', 'song_last_test']\n",
    "cat_cols_like = ['Market_Name', 'taa_quintile', 'segment', 'gcr', 'gcr_adj', 'omt_co_flag']\n",
    "target = ['pop_all']\n",
    "id_cols = ['mediabase_id', 'station_id', 'week_dt', 'breakout_id', 'breakout_name', 'demo_category', 'pop_co', 'pop_omt', 'gcr']\n",
    "\n",
    "exclude_cols_like = ['date','song_last_test_any_weeks','song_last_test_co_weeks', 'song_last_test_omt_weeks',\n",
    "                     'std_pop_prior', 'std_pop_artist_prior']#,'_unv']#,'univ_spins', 'market_spins']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "id_cols = id_cols\n",
    "target_col = target\n",
    "exclude_cols = df_train.columns[df_train.columns.str.contains('|'.join(exclude_cols_like), regex=True)]\n",
    "\n",
    "cat_cols = list(set(df_train.columns[df_train.columns.str.contains('|'.join(cat_cols_like), regex=True)]) - set(\n",
    "    id_cols) - set(exclude_cols))\n",
    "\n",
    "num_cols = list(set(df_train.select_dtypes(exclude=['object', 'datetime64']).columns) & set(\n",
    "df_train.columns[(df_train.columns.str.contains('|'.join(num_cols_like), regex=True))]) - set(id_cols) - set(cat_cols) - set(exclude_cols))\n",
    "\n",
    "feature_cols = list(set(list(num_cols) + list(cat_cols)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### investigate & impute numeric columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Investigate Numeric Columns\n",
    "num_cols_spins = [col for col in num_cols if 'spins' in col]\n",
    "num_cols_pop = [col for col in num_cols if 'pop' in col]\n",
    "num_cols_other = list(set(num_cols) - set(num_cols_spins) - set(num_cols_pop))\n",
    "num_cols_spins_perc = [i for i in num_cols_spins if (('perc_diff_' in i) or ('per_diff' in i))]\n",
    "num_cols_spins_nonperc = list(set(num_cols_spins) - set(num_cols_spins_perc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Backfill pop based data\n",
    "df_train[num_cols_pop] = df_train.groupby(['station_id', 'mediabase_id', 'breakout_id'])[num_cols_pop].bfill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Fill missing perc spin diffs with 1.0\n",
    "df_train[num_cols_spins_perc] = df_train[num_cols_spins_perc].transform(lambda x: x.fillna(1.0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Backfill non perc diff spins diff\n",
    "df_train[num_cols_spins_nonperc] = df_train.groupby(['station_id', 'mediabase_id', 'breakout_id'])[num_cols_spins_nonperc].bfill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "(377628, 110)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = df_train[cat_cols + num_cols].dropna(axis=1).index\n",
    "df_train.loc[idx].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "(377628, 110)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prep Data and create train/test splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Extract train data\n",
    "[np.min(df_train['week_dt']),pd.to_datetime(np.min(df_train['week_dt'])) + np.timedelta64(2,'Y'), np.max(df_train['week_dt'])]\n",
    "scoring_date = pd.to_datetime('2022-11-22')\n",
    "train_idx = df_train['week_dt'] < scoring_date.date()\n",
    "\n",
    "df_train_final = df_train.loc[train_idx][id_cols + feature_cols + target_col]\n",
    "X_train = pd.get_dummies(df_train_final[feature_cols], columns=cat_cols)\n",
    "y_train = df_train_final[target]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "demo_cats = list(set(breakout_category.values()) - set(['Total']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "(369153, 125)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# imports for model training\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GroupKFold\n",
    "from sklearn.metrics import make_scorer, mean_pinball_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "low_alpha = 0.05\n",
    "high_alpha = 0.95\n",
    "\n",
    "param_grid = dict(\n",
    "    learning_rate=[.2, .1, .05],\n",
    "    n_estimators=[5, 10, 15],\n",
    "    max_depth=[2, 4, 6],\n",
    "    min_samples_leaf=[5, 10, 20],\n",
    "    min_samples_split=[5, 10, 20]\n",
    ")\n",
    "\n",
    "n_iter = 50\n",
    "n_splits = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import time\n",
    "demo_cols_all = [col for col in X_train.columns if 'segment_' in col]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_scores = {}\n",
    "best_estimators = {}\n",
    "\n",
    "for cat in demo_cats:\n",
    "    tic = time.perf_counter()\n",
    "    idx = (df_train_final['demo_category'] == cat)\n",
    "    print(cat + ': ' + str(sum(idx)))\n",
    "\n",
    "    # extract relevant segment indicator columns\n",
    "    demo_cols_cat = ['segment_' + i for i in list(pd.unique(df_train_final.loc[idx]['segment']))]\n",
    "    demo_cols_excl = list(set(demo_cols_all) - set(demo_cols_cat))\n",
    "    feature_cols_cat = list(set(X_train.columns) - set(demo_cols_excl))\n",
    "\n",
    "    # create features and target\n",
    "    X = X_train.loc[idx][feature_cols_cat]\n",
    "    y = y_train.loc[idx]\n",
    "\n",
    "    # quantile regressor\n",
    "\n",
    "    # gradient boosted quantile regressor\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    # train model for upper threshold given features\n",
    "    cv = group_kfold.split(X.loc[idx], y.loc[idx], df_train_final.loc[idx]['mediabase_id'])\n",
    "    neg_mean_pinball_loss_high = make_scorer(\n",
    "        mean_pinball_loss,\n",
    "        alpha=high_alpha,\n",
    "        greater_is_better=False,  # maximize the negative loss\n",
    "    )\n",
    "\n",
    "    model_high_thresh = GradientBoostingRegressor(loss=\"quantile\", alpha=high_alpha,\n",
    "                                                  random_state=0)\n",
    "\n",
    "    rs_high_thresh = RandomizedSearchCV(\n",
    "        model_high_thresh,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        scoring=neg_mean_pinball_loss_high,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rs_high_thresh.fit(X.loc[idx], np.ravel(y.loc[idx]))\n",
    "    print(cat + \": Fitting for upper wobble threshold completed\")\n",
    "\n",
    "    # train model for lower threshold given features\n",
    "    cv = group_kfold.split(X.loc[idx], y.loc[idx], df_train_final.loc[idx]['mediabase_id'])\n",
    "    neg_mean_pinball_loss_low = make_scorer(\n",
    "        mean_pinball_loss,\n",
    "        alpha=low_alpha,\n",
    "        greater_is_better=False,  # maximize the negative loss\n",
    "    )\n",
    "\n",
    "    model_low_thresh = GradientBoostingRegressor(loss=\"quantile\", alpha=low_alpha,\n",
    "                                                 random_state=0)\n",
    "\n",
    "    rs_low_thresh = RandomizedSearchCV(\n",
    "        model_low_thresh,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        scoring=neg_mean_pinball_loss_low,\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rs_low_thresh.fit(X.loc[idx], np.ravel(y.loc[idx]))\n",
    "    print(cat + \": Fitting for lower wobble threshold completed\")\n",
    "\n",
    "    # train model for mean pop score given features\n",
    "    cv = group_kfold.split(X.loc[idx], y.loc[idx], df_train_final.loc[idx]['mediabase_id'])\n",
    "    model_mean = GradientBoostingRegressor(loss=\"squared_error\")\n",
    "\n",
    "    rs_mean = RandomizedSearchCV(\n",
    "        model_mean,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rs_mean.fit(X.loc[idx], np.ravel(y.loc[idx]))\n",
    "    print(cat + \": Fitting for mean pop completed\")\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    time_elapsed = toc-tic\n",
    "    print('Total time elapsed for ' + cat + ': ' + '%.2f'%time_elapsed)\n",
    "\n",
    "    best_scores[cat] = [rs_low_thresh.best_score_, rs_mean.best_score_, rs_high_thresh.best_score_]\n",
    "    best_estimators[cat] = [rs_low_thresh.best_estimator_, rs_mean.best_estimator_, rs_high_thresh.best_estimator_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_scores, open('best_scores_all.pkl', \"wb\"))\n",
    "pickle.dump(best_estimators, open('best_estimators_all.pkl', \"wb\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "best_estimators = pd.read_pickle('best_estimators_all.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Age': [GradientBoostingRegressor(alpha=0.05, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0),\n  GradientBoostingRegressor(learning_rate=0.2, max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15),\n  GradientBoostingRegressor(alpha=0.95, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0)],\n 'Gender': [GradientBoostingRegressor(alpha=0.05, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0),\n  GradientBoostingRegressor(learning_rate=0.2, max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15),\n  GradientBoostingRegressor(alpha=0.95, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0)],\n 'Race': [GradientBoostingRegressor(alpha=0.05, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0),\n  GradientBoostingRegressor(learning_rate=0.2, max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15),\n  GradientBoostingRegressor(alpha=0.95, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0)],\n 'Core-Cume': [GradientBoostingRegressor(alpha=0.05, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0),\n  GradientBoostingRegressor(learning_rate=0.2, max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15),\n  GradientBoostingRegressor(alpha=0.95, learning_rate=0.2, loss='quantile',\n                            max_depth=6, min_samples_leaf=10,\n                            min_samples_split=20, n_estimators=15,\n                            random_state=0)]}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prep scoring data & score\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "test_data_query = '''\n",
    "Select *\n",
    "from adds_temp.demo_rr_features_h1 as rdfh\n",
    "where week_dt >= '2022-11-29'\n",
    "and breakout_name = 'Total'\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "engine = postgresql_engine(user, pwd, host, port, dbname)\n",
    "with engine.connect() as conn:\n",
    "    with conn.connect():\n",
    "        df_test = pd.read_sql(test_data_query + filter_rules, conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(656836, 108)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# create segment and category fields\n",
    "df_test['segment'] = df_test['breakout_name'].apply(func=(lambda x: breakout_map[x] if (x in breakout_map.keys()) else None))\n",
    "df_test['demo_category'] = df_test['breakout_name'].apply(func=(lambda x: breakout_category[x] if x in breakout_category.keys() else None))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# drop misc female breakouts\n",
    "drop_idx = df_test[(df_test['segment'] == 'Female') | (pd.isna(df_test['segment']))].index\n",
    "df_test.drop(drop_idx, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Backfill pop based data\n",
    "df_test[num_cols_pop] = df_test.groupby(['station_id', 'mediabase_id', 'breakout_id'])[num_cols_pop].bfill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Fill missing perc spin diffs with 1.0\n",
    "df_test[num_cols_spins_perc] = df_test[num_cols_spins_perc].transform(lambda x: x.fillna(1.0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Backfill non perc diff spins diff\n",
    "df_test[num_cols_spins_nonperc] = df_test.groupby(['station_id', 'mediabase_id', 'breakout_id'])[num_cols_spins_nonperc].bfill()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "df_test['omt_co_flag'] = df_test['omt_co_flag'].fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# drop rows with missing features\n",
    "drop_idx = list(set(df_test.index) - set(df_test[feature_cols].dropna().index))\n",
    "df_test.drop(drop_idx, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### score KIIS-FM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "scoring_date = pd.to_datetime('2022-12-11')\n",
    "test_idx = (df_test['week_dt'] >= scoring_date.date()) & (df_test['station_id'] == 3322022)\n",
    "\n",
    "df_test_final = df_test.loc[test_idx][id_cols + feature_cols + target_col]\n",
    "X_test = pd.get_dummies(df_test_final[feature_cols], columns=cat_cols)\n",
    "\n",
    "missing_cols = list(set(X_train.columns) - set(X_test.columns))\n",
    "\n",
    "y_test = df_test_final[target]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "        mediabase_id  station_id     week_dt  breakout_id breakout_name  \\\n1691         1086587     3322022  2022-12-11           -2     F (Other)   \n1692         1086587     3322022  2022-12-18           -2     F (Other)   \n1693         1086587     3322022  2022-12-25           -2     F (Other)   \n1694         1086587     3322022  2023-01-01           -2     F (Other)   \n1695         1086587     3322022  2023-01-08           -2     F (Other)   \n...              ...         ...         ...          ...           ...   \n656536       2779283     3322022  2023-01-01       414582           WAO   \n656537       2779283     3322022  2023-01-08       414582           WAO   \n656538       2779283     3322022  2023-01-15       414582           WAO   \n656539       2779283     3322022  2023-01-22       414582           WAO   \n656540       2779283     3322022  2023-01-29       414582           WAO   \n\n       demo_category  pop_co pop_omt gcr  max_pop_artist_prior  ...  \\\n1691          Gender     NaN    None   R                  94.0  ...   \n1692          Gender     NaN    None   R                  94.0  ...   \n1693          Gender     NaN    None   R                  94.0  ...   \n1694          Gender     NaN    None   R                  94.0  ...   \n1695          Gender     NaN    None   R                  94.0  ...   \n...              ...     ...     ...  ..                   ...  ...   \n656536          Race     NaN    None   R                  90.0  ...   \n656537          Race     NaN    None   R                  90.0  ...   \n656538          Race     NaN    None   R                  90.0  ...   \n656539          Race     NaN    None   R                  90.0  ...   \n656540          Race     NaN    None   R                  90.0  ...   \n\n        song_market_weeks_since_first_spins  total_spins_song_station_prior  \\\n1691                                   26.0                           979.0   \n1692                                   27.0                           979.0   \n1693                                   28.0                           981.0   \n1694                                   29.0                           986.0   \n1695                                   30.0                           988.0   \n...                                     ...                             ...   \n656536                                 46.0                           683.0   \n656537                                 47.0                           684.0   \n656538                                 48.0                           685.0   \n656539                                 49.0                           685.0   \n656540                                 50.0                           685.0   \n\n        mr_pop_prior  mr_artist_univ_spins       segment  \\\n1691            81.0                 478.0  Female_Other   \n1692            81.0                 369.0  Female_Other   \n1693            81.0                 339.0  Female_Other   \n1694            81.0                 678.0  Female_Other   \n1695            81.0                 632.0  Female_Other   \n...              ...                   ...           ...   \n656536          72.0                 524.0         White   \n656537          72.0                 574.0         White   \n656538          72.0                 474.0         White   \n656539          72.0                 377.0         White   \n656540          72.0                 228.0         White   \n\n        per_diff_market_spins_spins_prior  station_artist_spins  \\\n1691                            -1.000000                     0   \n1692                             1.000000                     2   \n1693                            -0.166667                     5   \n1694                            -0.475000                     2   \n1695                            -1.000000                     0   \n...                                   ...                   ...   \n656536                          -0.500000                    11   \n656537                           0.000000                     7   \n656538                          -1.000000                     0   \n656539                           1.000000                     0   \n656540                           1.000000                     0   \n\n        diff_market_artist_spins_prior  diff_spins_song_station_prior  pop_all  \n1691                               -49                             -1      NaN  \n1692                                48                              2      NaN  \n1693                                -8                              3      NaN  \n1694                               -19                             -3      NaN  \n1695                               -21                             -2      NaN  \n...                                ...                            ...      ...  \n656536                               9                             -1      NaN  \n656537                              -4                              0      NaN  \n656538                              -7                             -1      NaN  \n656539                               0                              0      NaN  \n656540                               0                              0      NaN  \n\n[19257 rows x 90 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mediabase_id</th>\n      <th>station_id</th>\n      <th>week_dt</th>\n      <th>breakout_id</th>\n      <th>breakout_name</th>\n      <th>demo_category</th>\n      <th>pop_co</th>\n      <th>pop_omt</th>\n      <th>gcr</th>\n      <th>max_pop_artist_prior</th>\n      <th>...</th>\n      <th>song_market_weeks_since_first_spins</th>\n      <th>total_spins_song_station_prior</th>\n      <th>mr_pop_prior</th>\n      <th>mr_artist_univ_spins</th>\n      <th>segment</th>\n      <th>per_diff_market_spins_spins_prior</th>\n      <th>station_artist_spins</th>\n      <th>diff_market_artist_spins_prior</th>\n      <th>diff_spins_song_station_prior</th>\n      <th>pop_all</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1691</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2022-12-11</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>94.0</td>\n      <td>...</td>\n      <td>26.0</td>\n      <td>979.0</td>\n      <td>81.0</td>\n      <td>478.0</td>\n      <td>Female_Other</td>\n      <td>-1.000000</td>\n      <td>0</td>\n      <td>-49</td>\n      <td>-1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1692</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2022-12-18</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>94.0</td>\n      <td>...</td>\n      <td>27.0</td>\n      <td>979.0</td>\n      <td>81.0</td>\n      <td>369.0</td>\n      <td>Female_Other</td>\n      <td>1.000000</td>\n      <td>2</td>\n      <td>48</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1693</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2022-12-25</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>94.0</td>\n      <td>...</td>\n      <td>28.0</td>\n      <td>981.0</td>\n      <td>81.0</td>\n      <td>339.0</td>\n      <td>Female_Other</td>\n      <td>-0.166667</td>\n      <td>5</td>\n      <td>-8</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1694</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2023-01-01</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>94.0</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>986.0</td>\n      <td>81.0</td>\n      <td>678.0</td>\n      <td>Female_Other</td>\n      <td>-0.475000</td>\n      <td>2</td>\n      <td>-19</td>\n      <td>-3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2023-01-08</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>94.0</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>988.0</td>\n      <td>81.0</td>\n      <td>632.0</td>\n      <td>Female_Other</td>\n      <td>-1.000000</td>\n      <td>0</td>\n      <td>-21</td>\n      <td>-2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>656536</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-01</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>90.0</td>\n      <td>...</td>\n      <td>46.0</td>\n      <td>683.0</td>\n      <td>72.0</td>\n      <td>524.0</td>\n      <td>White</td>\n      <td>-0.500000</td>\n      <td>11</td>\n      <td>9</td>\n      <td>-1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>656537</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-08</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>90.0</td>\n      <td>...</td>\n      <td>47.0</td>\n      <td>684.0</td>\n      <td>72.0</td>\n      <td>574.0</td>\n      <td>White</td>\n      <td>0.000000</td>\n      <td>7</td>\n      <td>-4</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>656538</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-15</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>90.0</td>\n      <td>...</td>\n      <td>48.0</td>\n      <td>685.0</td>\n      <td>72.0</td>\n      <td>474.0</td>\n      <td>White</td>\n      <td>-1.000000</td>\n      <td>0</td>\n      <td>-7</td>\n      <td>-1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>656539</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-22</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>90.0</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>685.0</td>\n      <td>72.0</td>\n      <td>377.0</td>\n      <td>White</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>656540</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-29</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>90.0</td>\n      <td>...</td>\n      <td>50.0</td>\n      <td>685.0</td>\n      <td>72.0</td>\n      <td>228.0</td>\n      <td>White</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>19257 rows Ã— 90 columns</p>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "        max_pop_artist_prior  max_pop_prior_unv  min_pop_prior_unv  \\\n1691                    94.0               99.0               50.0   \n1692                    94.0               99.0               50.0   \n1693                    94.0               99.0               50.0   \n1694                    94.0               99.0               50.0   \n1695                    94.0               99.0               50.0   \n...                      ...                ...                ...   \n656536                  90.0               93.0               47.0   \n656537                  90.0               93.0               47.0   \n656538                  90.0               93.0               47.0   \n656539                  90.0               93.0               47.0   \n656540                  90.0               93.0               47.0   \n\n        diff_song_univ_spins_prior  avg_song_univ_spins_prior  \\\n1691                        -109.0                3233.481481   \n1692                         -30.0                3131.178571   \n1693                         339.0                3034.896552   \n1694                         -46.0                2956.333333   \n1695                        -533.0                2881.354839   \n...                            ...                        ...   \n656536                        13.0                 654.531915   \n656537                       -69.0                 642.354167   \n656538                        41.0                 629.265306   \n656539                       -41.0                 617.520000   \n656540                         0.0                 605.431373   \n\n        total_station_artist_spins_prior  diff_spins_song_market_prior  \\\n1691                               979.0                            -1   \n1692                               979.0                             2   \n1693                               981.0                             3   \n1694                               986.0                            -3   \n1695                               988.0                            -2   \n...                                  ...                           ...   \n656536                             692.0                            -1   \n656537                             703.0                             0   \n656538                             710.0                            -1   \n656539                             710.0                             0   \n656540                             710.0                             0   \n\n        total_song_univ_spins_prior  total_spins_non_on_song_station_prior  \\\n1691                        87304.0                                  724.0   \n1692                        87673.0                                  724.0   \n1693                        88012.0                                  726.0   \n1694                        88690.0                                  731.0   \n1695                        89322.0                                  733.0   \n...                             ...                                    ...   \n656536                      30763.0                                  473.0   \n656537                      30833.0                                  474.0   \n656538                      30834.0                                  475.0   \n656539                      30876.0                                  475.0   \n656540                      30877.0                                  475.0   \n\n        diff_artist_univ_spins_prior  ...  count_pop_prior_unv  \\\n1691                          -109.0  ...                292.0   \n1692                           -30.0  ...                292.0   \n1693                           339.0  ...                292.0   \n1694                           -46.0  ...                300.0   \n1695                          -533.0  ...                300.0   \n...                              ...  ...                  ...   \n656536                          50.0  ...                 33.0   \n656537                        -100.0  ...                 33.0   \n656538                         -97.0  ...                 33.0   \n656539                        -149.0  ...                 33.0   \n656540                         -47.0  ...                 33.0   \n\n        song_market_weeks_since_first_spins  total_spins_song_station_prior  \\\n1691                                   26.0                           979.0   \n1692                                   27.0                           979.0   \n1693                                   28.0                           981.0   \n1694                                   29.0                           986.0   \n1695                                   30.0                           988.0   \n...                                     ...                             ...   \n656536                                 46.0                           683.0   \n656537                                 47.0                           684.0   \n656538                                 48.0                           685.0   \n656539                                 49.0                           685.0   \n656540                                 50.0                           685.0   \n\n        mr_pop_prior  mr_artist_univ_spins       segment  \\\n1691            81.0                 478.0  Female_Other   \n1692            81.0                 369.0  Female_Other   \n1693            81.0                 339.0  Female_Other   \n1694            81.0                 678.0  Female_Other   \n1695            81.0                 632.0  Female_Other   \n...              ...                   ...           ...   \n656536          72.0                 524.0         White   \n656537          72.0                 574.0         White   \n656538          72.0                 474.0         White   \n656539          72.0                 377.0         White   \n656540          72.0                 228.0         White   \n\n        per_diff_market_spins_spins_prior  station_artist_spins  \\\n1691                            -1.000000                     0   \n1692                             1.000000                     2   \n1693                            -0.166667                     5   \n1694                            -0.475000                     2   \n1695                            -1.000000                     0   \n...                                   ...                   ...   \n656536                          -0.500000                    11   \n656537                           0.000000                     7   \n656538                          -1.000000                     0   \n656539                           1.000000                     0   \n656540                           1.000000                     0   \n\n        diff_market_artist_spins_prior  diff_spins_song_station_prior  \n1691                               -49                             -1  \n1692                                48                              2  \n1693                                -8                              3  \n1694                               -19                             -3  \n1695                               -21                             -2  \n...                                ...                            ...  \n656536                               9                             -1  \n656537                              -4                              0  \n656538                              -7                             -1  \n656539                               0                              0  \n656540                               0                              0  \n\n[19257 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>max_pop_artist_prior</th>\n      <th>max_pop_prior_unv</th>\n      <th>min_pop_prior_unv</th>\n      <th>diff_song_univ_spins_prior</th>\n      <th>avg_song_univ_spins_prior</th>\n      <th>total_station_artist_spins_prior</th>\n      <th>diff_spins_song_market_prior</th>\n      <th>total_song_univ_spins_prior</th>\n      <th>total_spins_non_on_song_station_prior</th>\n      <th>diff_artist_univ_spins_prior</th>\n      <th>...</th>\n      <th>count_pop_prior_unv</th>\n      <th>song_market_weeks_since_first_spins</th>\n      <th>total_spins_song_station_prior</th>\n      <th>mr_pop_prior</th>\n      <th>mr_artist_univ_spins</th>\n      <th>segment</th>\n      <th>per_diff_market_spins_spins_prior</th>\n      <th>station_artist_spins</th>\n      <th>diff_market_artist_spins_prior</th>\n      <th>diff_spins_song_station_prior</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1691</th>\n      <td>94.0</td>\n      <td>99.0</td>\n      <td>50.0</td>\n      <td>-109.0</td>\n      <td>3233.481481</td>\n      <td>979.0</td>\n      <td>-1</td>\n      <td>87304.0</td>\n      <td>724.0</td>\n      <td>-109.0</td>\n      <td>...</td>\n      <td>292.0</td>\n      <td>26.0</td>\n      <td>979.0</td>\n      <td>81.0</td>\n      <td>478.0</td>\n      <td>Female_Other</td>\n      <td>-1.000000</td>\n      <td>0</td>\n      <td>-49</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1692</th>\n      <td>94.0</td>\n      <td>99.0</td>\n      <td>50.0</td>\n      <td>-30.0</td>\n      <td>3131.178571</td>\n      <td>979.0</td>\n      <td>2</td>\n      <td>87673.0</td>\n      <td>724.0</td>\n      <td>-30.0</td>\n      <td>...</td>\n      <td>292.0</td>\n      <td>27.0</td>\n      <td>979.0</td>\n      <td>81.0</td>\n      <td>369.0</td>\n      <td>Female_Other</td>\n      <td>1.000000</td>\n      <td>2</td>\n      <td>48</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1693</th>\n      <td>94.0</td>\n      <td>99.0</td>\n      <td>50.0</td>\n      <td>339.0</td>\n      <td>3034.896552</td>\n      <td>981.0</td>\n      <td>3</td>\n      <td>88012.0</td>\n      <td>726.0</td>\n      <td>339.0</td>\n      <td>...</td>\n      <td>292.0</td>\n      <td>28.0</td>\n      <td>981.0</td>\n      <td>81.0</td>\n      <td>339.0</td>\n      <td>Female_Other</td>\n      <td>-0.166667</td>\n      <td>5</td>\n      <td>-8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1694</th>\n      <td>94.0</td>\n      <td>99.0</td>\n      <td>50.0</td>\n      <td>-46.0</td>\n      <td>2956.333333</td>\n      <td>986.0</td>\n      <td>-3</td>\n      <td>88690.0</td>\n      <td>731.0</td>\n      <td>-46.0</td>\n      <td>...</td>\n      <td>300.0</td>\n      <td>29.0</td>\n      <td>986.0</td>\n      <td>81.0</td>\n      <td>678.0</td>\n      <td>Female_Other</td>\n      <td>-0.475000</td>\n      <td>2</td>\n      <td>-19</td>\n      <td>-3</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>94.0</td>\n      <td>99.0</td>\n      <td>50.0</td>\n      <td>-533.0</td>\n      <td>2881.354839</td>\n      <td>988.0</td>\n      <td>-2</td>\n      <td>89322.0</td>\n      <td>733.0</td>\n      <td>-533.0</td>\n      <td>...</td>\n      <td>300.0</td>\n      <td>30.0</td>\n      <td>988.0</td>\n      <td>81.0</td>\n      <td>632.0</td>\n      <td>Female_Other</td>\n      <td>-1.000000</td>\n      <td>0</td>\n      <td>-21</td>\n      <td>-2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>656536</th>\n      <td>90.0</td>\n      <td>93.0</td>\n      <td>47.0</td>\n      <td>13.0</td>\n      <td>654.531915</td>\n      <td>692.0</td>\n      <td>-1</td>\n      <td>30763.0</td>\n      <td>473.0</td>\n      <td>50.0</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>46.0</td>\n      <td>683.0</td>\n      <td>72.0</td>\n      <td>524.0</td>\n      <td>White</td>\n      <td>-0.500000</td>\n      <td>11</td>\n      <td>9</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>656537</th>\n      <td>90.0</td>\n      <td>93.0</td>\n      <td>47.0</td>\n      <td>-69.0</td>\n      <td>642.354167</td>\n      <td>703.0</td>\n      <td>0</td>\n      <td>30833.0</td>\n      <td>474.0</td>\n      <td>-100.0</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>47.0</td>\n      <td>684.0</td>\n      <td>72.0</td>\n      <td>574.0</td>\n      <td>White</td>\n      <td>0.000000</td>\n      <td>7</td>\n      <td>-4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>656538</th>\n      <td>90.0</td>\n      <td>93.0</td>\n      <td>47.0</td>\n      <td>41.0</td>\n      <td>629.265306</td>\n      <td>710.0</td>\n      <td>-1</td>\n      <td>30834.0</td>\n      <td>475.0</td>\n      <td>-97.0</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>48.0</td>\n      <td>685.0</td>\n      <td>72.0</td>\n      <td>474.0</td>\n      <td>White</td>\n      <td>-1.000000</td>\n      <td>0</td>\n      <td>-7</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>656539</th>\n      <td>90.0</td>\n      <td>93.0</td>\n      <td>47.0</td>\n      <td>-41.0</td>\n      <td>617.520000</td>\n      <td>710.0</td>\n      <td>0</td>\n      <td>30876.0</td>\n      <td>475.0</td>\n      <td>-149.0</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>49.0</td>\n      <td>685.0</td>\n      <td>72.0</td>\n      <td>377.0</td>\n      <td>White</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>656540</th>\n      <td>90.0</td>\n      <td>93.0</td>\n      <td>47.0</td>\n      <td>0.0</td>\n      <td>605.431373</td>\n      <td>710.0</td>\n      <td>0</td>\n      <td>30877.0</td>\n      <td>475.0</td>\n      <td>-47.0</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>50.0</td>\n      <td>685.0</td>\n      <td>72.0</td>\n      <td>228.0</td>\n      <td>White</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>19257 rows Ã— 80 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_final[feature_cols].dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Market_Name_Atlanta',\n 'Market_Name_Austin',\n 'Market_Name_Baltimore',\n 'Market_Name_Boston',\n 'Market_Name_Charlotte',\n 'Market_Name_Chicago',\n 'Market_Name_Cincinnati',\n 'Market_Name_Columbus, OH',\n 'Market_Name_Dallas',\n 'Market_Name_Denver',\n 'Market_Name_Detroit',\n 'Market_Name_Miami',\n 'Market_Name_Minneapolis',\n 'Market_Name_Nashville',\n 'Market_Name_New York',\n 'Market_Name_Orlando',\n 'Market_Name_Philadelphia',\n 'Market_Name_Phoenix',\n 'Market_Name_Pittsburgh',\n 'Market_Name_Portland, OR',\n 'Market_Name_Raleigh',\n 'Market_Name_Salt Lake City',\n 'Market_Name_San Diego',\n 'Market_Name_San Francisco',\n 'Market_Name_Seattle',\n 'Market_Name_St. Louis',\n 'Market_Name_Tampa',\n 'Market_Name_Washington, DC',\n 'omt_co_flag_OMT_CO',\n 'omt_co_flag_OMT_only',\n 'segment_AA'}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_train.columns) - set(X_test.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "for i in missing_cols:\n",
    "    X_test[i] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "X_test = X_test[X_train.columns]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1], dtype=uint8)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(X_test['omt_co_flag_CO_only'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: 3108\n",
      "Race: 4583\n",
      "Core-Cume: 4626\n",
      "Age: 4626\n"
     ]
    }
   ],
   "source": [
    "df_out = pd.DataFrame(columns=['lower_wob_thresh', 'mean_pop_predicted', 'upper_wobble_thresh'])\n",
    "for cat in demo_cats:\n",
    "    #tic = time.perf_counter()\n",
    "    idx = (df_test_final['demo_category'] == cat)\n",
    "    print(cat + ': ' + str(sum(idx)))\n",
    "\n",
    "    # extract relevant segment indicator columns\n",
    "    demo_cols_cat = ['segment_' + i for i in list(pd.unique(df_test_final.loc[idx]['segment']))]\n",
    "    demo_cols_excl = list(set(demo_cols_all) - set(demo_cols_cat))\n",
    "    feature_cols_cat = list(set(X_test.columns) - set(demo_cols_excl))\n",
    "\n",
    "    # create features and target\n",
    "    X = X_test.loc[idx][feature_cols_cat]\n",
    "    if cat == 'Race':\n",
    "        X['segment_AA'] = 0\n",
    "    y = y_test.loc[idx]\n",
    "    #print(X)\n",
    "\n",
    "    # create empty dataframe\n",
    "    df_temp = pd.DataFrame()\n",
    "    # predict using estimator\n",
    "\n",
    "    #re-arrange features\n",
    "\n",
    "    df_temp['lower_wob_thresh'] = pd.DataFrame(best_estimators[cat][0].predict(X[best_estimators[cat][0].feature_names_in_]), index=X_test.loc[idx].index)\n",
    "    df_temp['mean_pop_predicted'] = pd.DataFrame(best_estimators[cat][1].predict(X[best_estimators[cat][1].feature_names_in_]), index=X_test.loc[idx].index)\n",
    "    df_temp['upper_wobble_thresh'] = pd.DataFrame(best_estimators[cat][2].predict(X[best_estimators[cat][2].feature_names_in_]), index=X_test.loc[idx].index)\n",
    "\n",
    "    df_out = pd.concat([df_out,df_temp], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "        lower_wob_thresh  mean_pop_predicted  upper_wobble_thresh\n1691           69.018166           83.449665            98.077451\n1692           69.018166           83.449665            98.077451\n1693           69.747890           83.639983            98.077451\n1694           68.851904           83.449665            98.077451\n1695           68.511838           83.212240            98.077451\n...                  ...                 ...                  ...\n656464         60.475703           74.660621            91.121738\n656465         58.755278           73.899343            91.121738\n656466         60.485782           74.325760            91.121738\n656467         58.933434           73.899343            91.121738\n656468         60.485782           74.930536            91.121738\n\n[16943 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lower_wob_thresh</th>\n      <th>mean_pop_predicted</th>\n      <th>upper_wobble_thresh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1691</th>\n      <td>69.018166</td>\n      <td>83.449665</td>\n      <td>98.077451</td>\n    </tr>\n    <tr>\n      <th>1692</th>\n      <td>69.018166</td>\n      <td>83.449665</td>\n      <td>98.077451</td>\n    </tr>\n    <tr>\n      <th>1693</th>\n      <td>69.747890</td>\n      <td>83.639983</td>\n      <td>98.077451</td>\n    </tr>\n    <tr>\n      <th>1694</th>\n      <td>68.851904</td>\n      <td>83.449665</td>\n      <td>98.077451</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>68.511838</td>\n      <td>83.212240</td>\n      <td>98.077451</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>656464</th>\n      <td>60.475703</td>\n      <td>74.660621</td>\n      <td>91.121738</td>\n    </tr>\n    <tr>\n      <th>656465</th>\n      <td>58.755278</td>\n      <td>73.899343</td>\n      <td>91.121738</td>\n    </tr>\n    <tr>\n      <th>656466</th>\n      <td>60.485782</td>\n      <td>74.325760</td>\n      <td>91.121738</td>\n    </tr>\n    <tr>\n      <th>656467</th>\n      <td>58.933434</td>\n      <td>73.899343</td>\n      <td>91.121738</td>\n    </tr>\n    <tr>\n      <th>656468</th>\n      <td>60.485782</td>\n      <td>74.930536</td>\n      <td>91.121738</td>\n    </tr>\n  </tbody>\n</table>\n<p>16943 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "df_out.to_pickle('df_out_stage_01292023_02052021.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process output & write to Excel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "df_out_final = df_test_final[id_cols + ['taa_quintile']].join(df_out, how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "df_out_final['segment'] = df_out_final['breakout_name'].apply(func=(lambda x: breakout_map[x] if (x in breakout_map.keys()) else None))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "        mediabase_id  station_id     week_dt  breakout_id breakout_name  \\\n1691         1086587     3322022  2022-12-11           -2     F (Other)   \n1692         1086587     3322022  2022-12-18           -2     F (Other)   \n1693         1086587     3322022  2022-12-25           -2     F (Other)   \n1694         1086587     3322022  2023-01-01           -2     F (Other)   \n1695         1086587     3322022  2023-01-08           -2     F (Other)   \n...              ...         ...         ...          ...           ...   \n656536       2779283     3322022  2023-01-01       414582           WAO   \n656537       2779283     3322022  2023-01-08       414582           WAO   \n656538       2779283     3322022  2023-01-15       414582           WAO   \n656539       2779283     3322022  2023-01-22       414582           WAO   \n656540       2779283     3322022  2023-01-29       414582           WAO   \n\n       demo_category  pop_co pop_omt gcr  taa_quintile  lower_wob_thresh  \\\n1691          Gender     NaN    None   R             5         69.018166   \n1692          Gender     NaN    None   R             5         69.018166   \n1693          Gender     NaN    None   R             5         69.747890   \n1694          Gender     NaN    None   R             5         68.851904   \n1695          Gender     NaN    None   R             5         68.511838   \n...              ...     ...     ...  ..           ...               ...   \n656536          Race     NaN    None   R             1         59.051873   \n656537          Race     NaN    None   R             1         58.871058   \n656538          Race     NaN    None   R             1         57.882549   \n656539          Race     NaN    None   R             1         58.871058   \n656540          Race     NaN    None   R             1         59.051873   \n\n        mean_pop_predicted  upper_wobble_thresh       segment  \n1691             83.449665            98.077451  Female_Other  \n1692             83.449665            98.077451  Female_Other  \n1693             83.639983            98.077451  Female_Other  \n1694             83.449665            98.077451  Female_Other  \n1695             83.212240            98.077451  Female_Other  \n...                    ...                  ...           ...  \n656536           71.220858            86.694550         White  \n656537           70.994946            85.891615         White  \n656538           71.798682            85.891615         White  \n656539           70.994946            85.891615         White  \n656540           70.994946            85.891615         White  \n\n[19257 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mediabase_id</th>\n      <th>station_id</th>\n      <th>week_dt</th>\n      <th>breakout_id</th>\n      <th>breakout_name</th>\n      <th>demo_category</th>\n      <th>pop_co</th>\n      <th>pop_omt</th>\n      <th>gcr</th>\n      <th>taa_quintile</th>\n      <th>lower_wob_thresh</th>\n      <th>mean_pop_predicted</th>\n      <th>upper_wobble_thresh</th>\n      <th>segment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1691</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2022-12-11</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>5</td>\n      <td>69.018166</td>\n      <td>83.449665</td>\n      <td>98.077451</td>\n      <td>Female_Other</td>\n    </tr>\n    <tr>\n      <th>1692</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2022-12-18</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>5</td>\n      <td>69.018166</td>\n      <td>83.449665</td>\n      <td>98.077451</td>\n      <td>Female_Other</td>\n    </tr>\n    <tr>\n      <th>1693</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2022-12-25</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>5</td>\n      <td>69.747890</td>\n      <td>83.639983</td>\n      <td>98.077451</td>\n      <td>Female_Other</td>\n    </tr>\n    <tr>\n      <th>1694</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2023-01-01</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>5</td>\n      <td>68.851904</td>\n      <td>83.449665</td>\n      <td>98.077451</td>\n      <td>Female_Other</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>1086587</td>\n      <td>3322022</td>\n      <td>2023-01-08</td>\n      <td>-2</td>\n      <td>F (Other)</td>\n      <td>Gender</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>5</td>\n      <td>68.511838</td>\n      <td>83.212240</td>\n      <td>98.077451</td>\n      <td>Female_Other</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>656536</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-01</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>1</td>\n      <td>59.051873</td>\n      <td>71.220858</td>\n      <td>86.694550</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>656537</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-08</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>1</td>\n      <td>58.871058</td>\n      <td>70.994946</td>\n      <td>85.891615</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>656538</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-15</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>1</td>\n      <td>57.882549</td>\n      <td>71.798682</td>\n      <td>85.891615</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>656539</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-22</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>1</td>\n      <td>58.871058</td>\n      <td>70.994946</td>\n      <td>85.891615</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>656540</th>\n      <td>2779283</td>\n      <td>3322022</td>\n      <td>2023-01-29</td>\n      <td>414582</td>\n      <td>WAO</td>\n      <td>Race</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>R</td>\n      <td>1</td>\n      <td>59.051873</td>\n      <td>70.994946</td>\n      <td>85.891615</td>\n      <td>White</td>\n    </tr>\n  </tbody>\n</table>\n<p>19257 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# song-artist lookup\n",
    "song_query = '''\n",
    "Select mediabase_id, song_name, artist_name\n",
    "from data.songs_v as sv\n",
    "'''\n",
    "engine = postgresql_engine(user, pwd, host, port, dbname)\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        df_song_lookup = pd.read_sql(song_query, con=conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "station_query = '''\n",
    "Select distinct station_id, call_letters\n",
    "from data.stations_v as sv\n",
    "'''\n",
    "\n",
    "engine = postgresql_engine(user, pwd, host, port, dbname)\n",
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        df_station_lookup = pd.read_sql(station_query, con=conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "df_song_lookup.set_index(['mediabase_id'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "df_station_lookup.set_index(['station_id'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "df_song_lookup['song_artist']  = df_song_lookup['song_name'] + ' (' + df_song_lookup['artist_name'] + ')'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   song_name          artist_name  \\\nmediabase_id                                                        \n1147620                   Mr. Crowley (Live)        OZZY OSBOURNE   \n1960216       Street Fighting Man (Live '13)       ROLLING STONES   \n2691117                     Storybook Ending               BLUMES   \n1804878           You Take My... (Live  '76)                QUEEN   \n2131197               Hero Of The Day (Live)            METALLICA   \n...                                      ...                  ...   \n2437613                      Valentine's Day  QUEEN OF THE MEADOW   \n2667991                         Exaggeration            JUAN HAZE   \n2438195                           Every Week                 DQ4E   \n2623051                  Your Story Is Over!               AYREON   \n2580022                     Greatness Of God    RANCE ALLEN GROUP   \n\n                                                  song_artist  \nmediabase_id                                                   \n1147620                    Mr. Crowley (Live) (OZZY OSBOURNE)  \n1960216       Street Fighting Man (Live '13) (ROLLING STONES)  \n2691117                             Storybook Ending (BLUMES)  \n1804878                    You Take My... (Live  '76) (QUEEN)  \n2131197                    Hero Of The Day (Live) (METALLICA)  \n...                                                       ...  \n2437613                 Valentine's Day (QUEEN OF THE MEADOW)  \n2667991                              Exaggeration (JUAN HAZE)  \n2438195                                     Every Week (DQ4E)  \n2623051                          Your Story Is Over! (AYREON)  \n2580022                  Greatness Of God (RANCE ALLEN GROUP)  \n\n[1547041 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_name</th>\n      <th>artist_name</th>\n      <th>song_artist</th>\n    </tr>\n    <tr>\n      <th>mediabase_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1147620</th>\n      <td>Mr. Crowley (Live)</td>\n      <td>OZZY OSBOURNE</td>\n      <td>Mr. Crowley (Live) (OZZY OSBOURNE)</td>\n    </tr>\n    <tr>\n      <th>1960216</th>\n      <td>Street Fighting Man (Live '13)</td>\n      <td>ROLLING STONES</td>\n      <td>Street Fighting Man (Live '13) (ROLLING STONES)</td>\n    </tr>\n    <tr>\n      <th>2691117</th>\n      <td>Storybook Ending</td>\n      <td>BLUMES</td>\n      <td>Storybook Ending (BLUMES)</td>\n    </tr>\n    <tr>\n      <th>1804878</th>\n      <td>You Take My... (Live  '76)</td>\n      <td>QUEEN</td>\n      <td>You Take My... (Live  '76) (QUEEN)</td>\n    </tr>\n    <tr>\n      <th>2131197</th>\n      <td>Hero Of The Day (Live)</td>\n      <td>METALLICA</td>\n      <td>Hero Of The Day (Live) (METALLICA)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2437613</th>\n      <td>Valentine's Day</td>\n      <td>QUEEN OF THE MEADOW</td>\n      <td>Valentine's Day (QUEEN OF THE MEADOW)</td>\n    </tr>\n    <tr>\n      <th>2667991</th>\n      <td>Exaggeration</td>\n      <td>JUAN HAZE</td>\n      <td>Exaggeration (JUAN HAZE)</td>\n    </tr>\n    <tr>\n      <th>2438195</th>\n      <td>Every Week</td>\n      <td>DQ4E</td>\n      <td>Every Week (DQ4E)</td>\n    </tr>\n    <tr>\n      <th>2623051</th>\n      <td>Your Story Is Over!</td>\n      <td>AYREON</td>\n      <td>Your Story Is Over! (AYREON)</td>\n    </tr>\n    <tr>\n      <th>2580022</th>\n      <td>Greatness Of God</td>\n      <td>RANCE ALLEN GROUP</td>\n      <td>Greatness Of God (RANCE ALLEN GROUP)</td>\n    </tr>\n  </tbody>\n</table>\n<p>1547041 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_song_lookup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "df_out_final['song_artist'] = df_out_final.join(df_song_lookup, on=['mediabase_id'], how='left')['song_artist']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "df_out_final['call_letters'] = df_out_final.join(df_station_lookup, on=['station_id'], how='left')['call_letters']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "df_out_final['wobble_flag'] = df_out_final.apply(lambda x: int((x['pop_co'] < np.floor(x['lower_wob_thresh'])) | (x['pop_co'] > np.ceil(x['upper_wobble_thresh']))), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "df_out_final.to_pickle('df_out_final_KIIS-FM_2022_12_11_2023_01_29.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
